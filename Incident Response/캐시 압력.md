# 캐시 압력(Cache Pressure)의 이해와 해결 방법

## 1. 캐시 압력이란?

캐시 압력은 캐시 메모리가 부족해지면서 발생하는 문제를 말한다. 캐시가 가득 차서 더 이상 새로운 데이터를 저장할 수 없고, 이로 인해 기존 데이터를 삭제해야 하는 상황이 발생할 수 있다. 캐시 압력이 증가하면, 캐시 항목을 삭제하거나 새 데이터를 캐시에 저장하는 동안 대기 상태가 발생할 수 있다.

## 2. 캐시 압력 발생 상황

스프링에서 사용자별 페이징 데이터를 캐시에 저장하는 경우, 특히 대규모 사용자와 많은 데이터를 처리하는 시스템에서는 캐시 메모리가 빠르게 소진될 수 있으며, 이는 "캐시 쓰로틀링(Cache Throttling)" 또는 "캐시 압력(Cache Pressure)" 상황을 초래할 수 있다.

이러한 상황은 캐시가 가득 차서 새로운 데이터를 저장할 수 없게 되어 요청이 지연되거나, 대기 상태로 빠지는 문제를 일으킬 수 있다.

## 3. 문제 상황

### 3.1 데이터량 증가
* 각 사용자가 고유한 페이징 데이터를 요청할 경우, 캐시에 저장되는 데이터의 양이 빠르게 증가할 수 있다.
* 다양한 페이징 요청(예: 페이지 번호, 페이지 크기, 필터링 조건 등)에 따라 각기 다른 캐시 항목이 생성되어, 캐시 공간을 많이 차지하게 된다.

### 3.2 캐시 용량 초과
* 캐시는 일반적으로 제한된 메모리 공간을 사용한다. 사용자별로 많은 페이징 데이터를 캐시에 저장하면 캐시 용량이 초과될 수 있다.
* 용량 초과로 인해 캐시가 새로운 항목을 수용할 수 없게 되면, 기존 항목을 제거하거나 요청이 대기 상태로 전환될 수 있다.

### 3.3 캐시 히트율 저하
* 페이징 데이터를 캐시하는 경우, 사용자가 특정 페이지를 반복적으로 요청하지 않는 한 캐시 히트율이 낮아질 수 있다.
* 낮은 캐시 히트율은 캐시의 효율성을 떨어뜨리며, 메모리 낭비로 이어질 수 있다.

### 3.4 사용자별 캐시 공간 경쟁
* 다수의 사용자가 동일한 캐시 리소스를 공유할 때, 사용자별로 많은 데이터를 캐시에 저장하면 캐시 공간이 경쟁 상태가 되어, 중요한 데이터가 자주 제거될 수 있다.
* 이로 인해 필요한 데이터가 캐시에 존재하지 않아, 다시 데이터베이스에서 가져오는 상황이 빈번해질 수 있다.

## 4. 해결 방법

### 4.1 캐시 제한 설정

* **TTL(Time-To-Live)**: 캐시 항목에 TTL을 설정하여 일정 시간 후에 자동으로 만료되도록 설정할 수 있다. 이를 통해 오래된 캐시 데이터를 자동으로 제거하고, 새로운 항목을 저장할 공간을 확보할 수 있다.
* **최대 캐시 크기 설정**: 사용자별 페이징 데이터에 대해 캐시의 최대 크기를 설정하여, 용량이 초과되면 오래된 데이터를 자동으로 제거하도록 할 수 있다.

```java
@Configuration
@EnableCaching
public class CacheConfig {
    @Bean
    public CacheManager cacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager("pagingData");
        
        cacheManager.setCaffeine(Caffeine.newBuilder()
                .maximumSize(1000)  // 최대 항목 수 제한
                .expireAfterWrite(Duration.ofMinutes(5))  // 5분 후 만료
                .recordStats());  // 통계 수집 활성화
        
        return cacheManager;
    }
}
```

### 4.2 페이징 전략 최적화

* **부분적 캐싱**: 모든 페이지를 캐싱하기보다는 자주 요청되는 특정 페이지만을 캐싱하여, 캐시 공간을 효율적으로 사용할 수 있다.
  * 거의 모든 사용자가 1페이지를 많이 접속하게 되므로 1페이지만 캐싱한다.
* **데이터베이스 인덱스 최적화**: 캐시를 사용하는 대신, 데이터베이스 인덱스를 최적화하여 페이징 성능을 향상시킬 수 있다. 이렇게 하면 캐시 의존도를 줄이고, 데이터베이스에서 더 빠르게 결과를 가져올 수 있다.

```java
@Service
public class ItemService {
    private final ItemRepository itemRepository;
    
    @Cacheable(value = "pagingData", key = "'user_' + #userId + '_page_' + #page", 
               condition = "#page <= 3")  // 처음 3페이지만 캐싱
    public Page<Item> getItemsByUser(String userId, int page, int size) {
        return itemRepository.findByUserId(userId, PageRequest.of(page, size));
    }
}
```

### 4.3 분산 캐시 사용

Redis와 같은 분산 캐시 시스템을 사용하여, 여러 서버에 캐시 데이터를 분산시킬 수 있다. 이를 통해 한 서버의 메모리 용량 한계를 극복하고, 캐시 성능을 높일 수 있다.

```java
@Configuration
public class RedisConfig {
    @Bean
    public RedisConnectionFactory redisConnectionFactory() {
        return new LettuceConnectionFactory("redis-host", 6379);
    }
    
    @Bean
    public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) {
        RedisCacheConfiguration cacheConfig = RedisCacheConfiguration.defaultCacheConfig()
                .entryTtl(Duration.ofMinutes(10))  // 10분 TTL
                .disableCachingNullValues();
                
        return RedisCacheManager.builder(redisConnectionFactory)
                .cacheDefaults(cacheConfig)
                .build();
    }
}
```

### 4.4 캐시 우회 전략

특정 조건에서 캐시를 우회하고 직접 데이터베이스에서 데이터를 가져오는 전략을 사용할 수 있다. 예를 들어, 페이징 요청이 매우 세분화된 경우 캐시를 우회하도록 설정할 수 있다.

```java
@Service
public class DataService {
    private final DataRepository dataRepository;
    
    @Cacheable(value = "pagingData", 
               key = "'user_' + #userId + '_filter_' + #filter", 
               condition = "!#filter.contains('complex')")  // 복잡한 필터링은 캐시 우회
    public List<Data> getFilteredData(String userId, String filter) {
        return dataRepository.findByUserIdAndFilter(userId, filter);
    }
}
```

## 5. 구현 예시: 분리된 캐싱 전략

### 5.1 문제가 있는 캐싱 구조

Redis 캐시에서 다음과 같은 구조를 사용하면 캐시 크기가 커질 수 있다:

```json
{
  "user123_page_1": {
    "userId": "user123",
    "page": 1,
    "pageSize": 10,
    "totalPages": 5,
    "data": [
      {
        "id": "item1",
        "name": "Item One",
        "description": "Description for item one."
      },
      {
        "id": "item2",
        "name": "Item Two",
        "description": "Description for item two."
      }
    ]
  },
  "user123_page_2": {
    "userId": "user123",
    "page": 2,
    "pageSize": 10,
    "totalPages": 5,
    "data": [
      {
        "id": "item11",
        "name": "Item Eleven",
        "description": "Description for item eleven."
      },
      {
        "id": "item12",
        "name": "Item Twelve",
        "description": "Description for item twelve."
      }
    ]
  }
}
```

### 5.2 개선된 캐싱 전략

캐시 압력을 줄이기 위해 데이터를 분리하여 캐싱할 수 있다:

**페이징 데이터 캐싱:** 사용자가 요청한 페이지에 해당하는 항목들의 ID 리스트만 캐시에 저장한다:

```json
{
  "user123_page_1": ["item1", "item2", "item3"],
  "user123_page_2": ["item4", "item5", "item6"]
}
```

**아이템 데이터 캐싱:** 각 아이템에 대한 상세 데이터를 별도로 캐싱한다:

```json
{
  "item1": {
    "id": "item1",
    "name": "Item One",
    "description": "Description for item one."
  },
  "item2": {
    "id": "item2",
    "name": "Item Two",
    "description": "Description for item two."
  }
}
```

### 5.3 데이터 조회 및 조합 로직

사용자가 특정 페이지를 요청하면 다음 단계로 데이터를 처리한다:

1. **페이지 ID 리스트 가져오기**
   * 먼저, 요청된 페이지에 해당하는 페이징 데이터(ID 리스트)를 가져온다.

2. **아이템 상세 데이터 가져오기**
   * 위에서 가져온 각 아이템 ID에 대해 캐시된 상세 데이터를 조회한다.

3. **데이터 조합**
   * 가져온 아이템 상세 데이터를 조합하여 최종 결과를 생성한다.

결론적으로, 중복되는 영역을 분리하여 저장하므로써 공간 절약을 할 수 있다.

```java
@Service
public class PagingService {
    private final RedisTemplate<String, Object> redisTemplate;
    private final ItemRepository itemRepository;
    
    public List<Item> getPageItems(String userId, int page) {
        String pageKey = String.format("user%s_page_%d", userId, page);
        
        // 1. 페이지 ID 리스트 가져오기
        List<String> itemIds = (List<String>) redisTemplate.opsForValue().get(pageKey);
        
        if (itemIds == null) {
            // 캐시에 없으면 DB에서 조회하고 캐싱
            Page<Item> itemPage = itemRepository.findByUserId(userId, 
                                   PageRequest.of(page - 1, 10));
            
            itemIds = itemPage.getContent().stream()
                    .map(Item::getId)
                    .collect(Collectors.toList());
                    
            // 페이지 ID 리스트 캐싱 (5분 만료)
            redisTemplate.opsForValue().set(pageKey, itemIds, 5, TimeUnit.MINUTES);
            
            // 개별 아이템 캐싱 (30분 만료)
            for (Item item : itemPage.getContent()) {
                redisTemplate.opsForValue().set("item_" + item.getId(), 
                                              item, 30, TimeUnit.MINUTES);
            }
            
            return itemPage.getContent();
        }
        
        // 2. 아이템 상세 데이터 가져오기
        List<Item> items = new ArrayList<>();
        for (String itemId : itemIds) {
            String itemKey = "item_" + itemId;
            Item item = (Item) redisTemplate.opsForValue().get(itemKey);
            
            if (item == null) {
                // 캐시에 없으면 DB에서 조회
                item = itemRepository.findById(itemId)
                        .orElseThrow(() -> new ItemNotFoundException(itemId));
                
                // 아이템 캐싱
                redisTemplate.opsForValue().set(itemKey, item, 30, TimeUnit.MINUTES);
            }
            
            items.add(item);
        }
        
        // 3. 데이터 조합하여 반환
        return items;
    }
}
```

## 6. 캐시 백오프

일반적으로 캐시에 접근할 때 캐시 미스(cache miss)가 발생하면, 시스템은 데이터를 캐시에 다시 적재하거나 원본 데이터베이스에서 데이터를 가져와야 한다. 이 과정에서 여러 클라이언트가 동시에 캐시에 접근하거나 요청을 보내면, 캐시 서버나 원본 데이터베이스에 과부하가 걸릴 수 있다.



캐시 백오프는 이러한 과부하를 방지하기 위해, 캐시 미스가 발생했을 때 재시도 요청의 빈도를 줄이거나 일정한 대기 시간을 두는 전략이다. 이렇게 하면 캐시 미스 발생 시 즉각적으로 원본 데이터베이스나 캐시 서버에 다량의 요청이 몰리지 않도록 하여, 시스템이 정상적으로 복구할 시간을 벌 수 있다.

### 6.1 안전한 백오프 전략

1. **점진적 백오프 적용**:
   * 모든 캐시를 한번에 무효화하지 않고, 단계적으로 진행한다.
   * 일부 트래픽(예: 1%)에 대해 먼저 백오프를 적용하고, 문제가 없으면 점차 비율을 높인다.

2. **서킷 브레이커 패턴 적용**:
   * 데이터베이스 부하가 임계값을 초과하면 캐시 백오프를 중단하는 메커니즘을 구현한다.

```java
@Component
public class DatabaseLoadMonitor {
    private final DataSource dataSource;
    private AtomicBoolean highLoad = new AtomicBoolean(false);
    
    @Scheduled(fixedRate = 5000)
    public void checkDatabaseLoad() {
        try (Connection conn = dataSource.getConnection();
             PreparedStatement ps = conn.prepareStatement("SELECT pg_stat_activity.count FROM pg_stat_activity")) {
            ResultSet rs = ps.executeQuery();
            if (rs.next()) {
                int connections = rs.getInt(1);
                // 임계값 초과 시 high load 설정
                highLoad.set(connections > 100);
            }
        } catch (SQLException e) {
            log.error("Database load check failed", e);
        }
    }
    
    public boolean isHighLoad() {
        return highLoad.get();
    }
}

@Service
public class CacheableService {
    private final DatabaseLoadMonitor loadMonitor;
    
    @Cacheable(value = "data", condition = "!@databaseLoadMonitor.isHighLoad()")
    public Data getData(String id) {
        // 데이터베이스에서 데이터 조회
    }
}
```

3. **캐시 재생성 스케줄링**:
   * 시스템 부하가 적은 시간대에 캐시를 미리 재생성하는 작업을 스케줄링한다.

```java
@Component
public class CacheWarmer {
    private final DataService dataService;
    
    @Scheduled(cron = "0 0 3 * * *") // 매일 새벽 3시
    public void warmUpCache() {
        log.info("Starting cache warm-up");
        List<String> popularQueries = getPopularQueries();
        
        for (String query : popularQueries) {
            try {
                // 캐시 미리 생성
                dataService.getDataByQuery(query);
                Thread.sleep(100); // 부하 분산
            } catch (Exception e) {
                log.warn("Failed to warm up cache for query: {}", query, e);
            }
        }
        log.info("Cache warm-up completed");
    }
}
```

## 7. 캐시 모니터링

캐시 압력을 효과적으로 관리하기 위해서는 모니터링이 필수적이다.

### 7.1 주요 모니터링 지표

* **캐시 히트율**: 전체 요청 중 캐시에서 성공적으로 데이터를 가져온 비율
* **캐시 사용량**: 현재 캐시가 사용하고 있는 메모리 양
* **캐시 퇴거율**: 캐시에서 제거되는 항목의 비율
* **평균 응답 시간**: 캐시 사용 시와 미사용 시의 응답 시간 비교

### 7.2 모니터링 구현

```java
@Configuration
public class CacheMonitoringConfig {
    @Bean
    public CacheMetricsRegistrar cacheMetricsRegistrar(MeterRegistry registry, CacheManager cacheManager) {
        return new CacheMetricsRegistrar(registry, cacheManager);
    }
}

@Component
public class CacheMetricsRegistrar {
    private final MeterRegistry registry;
    private final CacheManager cacheManager;
    
    @PostConstruct
    public void registerMetrics() {
        if (cacheManager instanceof CaffeineCacheManager) {
            CaffeineCacheManager caffeineCacheManager = (CaffeineCacheManager) cacheManager;
            
            for (String cacheName : caffeineCacheManager.getCacheNames()) {
                Cache cache = caffeineCacheManager.getCache(cacheName);
                if (cache instanceof CaffeineCache) {
                    com.github.benmanes.caffeine.cache.Cache<Object, Object> nativeCache = 
                        ((CaffeineCache) cache).getNativeCache();
                    
                    // 히트율 측정
                    Gauge.builder("cache.hit.ratio", nativeCache, 
                           c -> c.stats().hitRate())
                         .tag("cache", cacheName)
                         .register(registry);
                    
                    // 캐시 크기 측정
                    Gauge.builder("cache.size", nativeCache,
                           c -> c.estimatedSize())
                         .tag("cache", cacheName)
                         .register(registry);
                    
                    // 퇴거율 측정
                    Gauge.builder("cache.eviction.count", nativeCache,
                           c -> c.stats().evictionCount())
                         .tag("cache", cacheName)
                         .register(registry);
                }
            }
        }
    }
}
```

## 8. 결론

캐시 압력은 대규모 시스템, 특히 많은 사용자와 데이터를 처리하는 환경에서 흔히 발생하는 문제이다. 적절한 캐시 제한 설정, 최적화된 캐싱 전략, 분산 캐시 사용, 그리고 효과적인 모니터링을 통해 캐시 압력 문제를 관리하고 시스템의 성능과 안정성을 유지할 수 있다.

특히 데이터를 분리하여 캐싱하는 전략(ID 리스트와 상세 데이터 분리)은 캐시 메모리 사용을 효율화하고, 재사용성을 높이는 좋은 방법이다. 또한, 캐시 백오프 전략을 사용할 때는 데이터베이스 부하를 고려한 점진적 접근이 중요하다.